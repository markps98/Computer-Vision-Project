{"cells":[{"cell_type":"markdown","metadata":{"id":"JxVrHOaHQyqB"},"source":["Author: Mark Ssenoga"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8PQXiarFLF5V"},"outputs":[],"source":["%pip install SoccerNet opencv-python ultralytics scikit-learn deep-sort-realtime numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Y5N01iAvQkm0"},"outputs":[],"source":["from SoccerNet.Downloader import SoccerNetDownloader\n","\n","mySoccerNetDownloader = SoccerNetDownloader(\n","    LocalDirectory=\"/content/drive/MyDrive/Research and Development Project/Datasets\"\n",")\n","\n","# Download SoccerNet videos\n","mySoccerNetDownloader.password = \"\"\n","mySoccerNetDownloader.downloadRAWVideo(dataset=\"SoccerNet-Tracking\")"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from deep_sort_realtime.deepsort_tracker import DeepSort\n","from sklearn.cluster import KMeans\n","from ultralytics import YOLO\n","\n","# Load YOLO models\n","model = YOLO('yolo11x.pt')\n","pose_model = YOLO('yolo11x-pose.pt')\n","\n","# Initialize DeepSORT\n","deep_sort = DeepSort()\n","\n","# Pose descriptor memory buffer\n","pose_memory = {}\n","\n","# Video paths\n","video_path = \"/content/drive/MyDrive/Research and Development Project/Datasets/1/1.mkv\"\n","output_path = \"output_processed.mp4\"\n","\n","# Frame limit\n","TARGET_FRAME_COUNT = 500\n","\n","# Confidence threshold\n","CONFIDENCE_THRESHOLD = 0.5\n","\n","# Color distance threshold\n","COLOR_DISTANCE_THRESHOLD = 50\n","\n","# Pose descriptor parameters\n","POSE_MEMORY_DURATION_FRAMES = 250\n","POSE_MATCH_THRESHOLD = 0.25\n","\n","# Normalize pose keypoints relative to bounding box size\n","def normalize_keypoints(keypoints, bbox):\n","    x1, y1, x2, y2 = bbox\n","    width = max(x2 - x1, 1)\n","    height = max(y2 - y1, 1)\n","    normalized = [(x / width, y / height) for (x, y, _) in keypoints]\n","    return np.array(normalized).flatten()\n","\n","# Store a pose descriptor in memory for a given track ID\n","def store_pose_descriptor(track_id, descriptor, frame_number):\n","    pose_memory[track_id] = (descriptor, frame_number)\n","\n","# Remove old pose descriptors that exceed memory duration\n","def clean_old_pose_descriptors(current_frame):\n","    old_ids = [tid for tid, (_, fnum) in pose_memory.items()\n","               if current_frame - fnum > POSE_MEMORY_DURATION_FRAMES]\n","    for tid in old_ids:\n","        del pose_memory[tid]\n","\n","# Find the best matching stored descriptor for a new descriptor\n","def find_best_pose_match(new_descriptor, current_frame):\n","    best_id = None\n","    best_dist = float('inf')\n","    for track_id, (stored_desc, frame_num) in pose_memory.items():\n","        if current_frame - frame_num <= POSE_MEMORY_DURATION_FRAMES:\n","            dist = np.linalg.norm(new_descriptor - stored_desc)\n","            if dist < best_dist and dist < POSE_MATCH_THRESHOLD:\n","                best_dist = dist\n","                best_id = track_id\n","    return best_id\n","\n","# Helper to compute dominant color in HSV\n","def get_dominant_color(image, k=1):\n","    data = image.reshape((-1, 3))\n","    if len(data) == 0:\n","        return None\n","    kmeans = KMeans(n_clusters=k, random_state=42).fit(data)\n","    return kmeans.cluster_centers_[0]\n","\n","# Function to draw pose keypoints within bounding box\n","def draw_pose_keypoints(frame, keypoints, bbox, confidence_threshold=0.5):\n","    x1, y1, x2, y2 = bbox\n","\n","    for (x, y, conf) in keypoints:\n","        if conf > confidence_threshold:\n","            # Transform keypoint coordinates relative to the bounding box\n","            rel_x = int(x1 + x)\n","            rel_y = int(y1 + y)\n","\n","            # Draw a circle for the keypoint\n","            cv2.circle(frame, (rel_x, rel_y), 5, (0, 0, 255), -1)\n","\n","    return frame\n","\n","# Main video processing\n","def process_video(video_path, output_path, skip_seconds, debug=False):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(\"Error: Could not open video.\")\n","        return\n","\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n","\n","    if skip_seconds > 0:\n","        print(f\"Skipping first {skip_seconds} seconds...\")\n","        for _ in range(int(fps) * skip_seconds):\n","            cap.read()\n","\n","    frame_count = 0\n","    color_samples = []\n","    locked_team_colors = None  # Will hold fixed centroids after enough samples\n","    all_confidences = []  # Collects confidence scores for YOLO player detections\n","\n","    while frame_count < TARGET_FRAME_COUNT:\n","        success, frame = cap.read()\n","        if not success:\n","            break\n","\n","        # YOLO Player Detection\n","        results = model(frame, verbose=False)\n","\n","        detections = results[0].boxes.data.cpu().numpy() \\\n","                     if results and results[0].boxes else []\n","        players = [det for det in detections\n","            if int(det[5]) == 0 and float(det[4]) >= CONFIDENCE_THRESHOLD\n","        ]\n","\n","        # Prepare the list of detections for Deep SORT\n","        bboxes = []\n","        scores = []\n","        for det in players:\n","            x1, y1, x2, y2 = map(int, det[:4])\n","            conf = float(det[4])\n","            bboxes.append([x1, y1, x2, y2])\n","            scores.append(conf)\n","            all_confidences.append(conf)\n","\n","        # Update Deep SORT tracker\n","        trackers = deep_sort.update_tracks(\n","            [[(x1, y1, x2 - x1, y2 - y1), score, 'player']\n","             for (x1, y1, x2, y2), score in zip(bboxes, scores)],\n","            frame=frame\n","        ) if bboxes else []\n","\n","        track_list = []\n","        for tracker in trackers:\n","            if not tracker.is_confirmed():\n","                continue # Skip unconfirmed tracks\n","\n","            x1, y1, x2, y2 = map(int, tracker.to_tlbr())\n","            player_conf = tracker.det_conf if tracker.det_conf is not None else 0.0\n","\n","            if player_conf == 0.0:  # Skip low confidence\n","                continue\n","\n","            # Extract pose keypoints (from YOLO pose model)\n","            player_frame = frame[y1:y2, x1:x2]\n","            descriptor = None\n","            matched_track_id = None\n","\n","            if player_frame.size != 0:\n","                pose_results = pose_model(player_frame, verbose=False)\n","\n","                if pose_results and pose_results[0].keypoints:\n","                    pose_keypoints = pose_results[0].keypoints.cpu().numpy().data[0]\n","\n","                    # Normalize keypoints for descriptor\n","                    descriptor = normalize_keypoints(pose_keypoints, (x1, y1, x2, y2))\n","\n","                    # Re-identify if possible\n","                    matched_track_id = find_best_pose_match(descriptor, frame_count)\n","\n","                    # Draw pose keypoints on frame\n","                    if debug:\n","                        frame = draw_pose_keypoints(frame, pose_keypoints, (x1, y1, x2, y2))\n","\n","            # Assign consistent track ID if re-identified\n","            if matched_track_id is not None and matched_track_id < tracker.track_id:\n","                if debug:\n","                    print(\n","                        f\"[Frame {frame_count}] \"\n","                        f\"Re-identified player - new ID: {tracker.track_id} -> {matched_track_id}\"\n","                    )\n","                tracker.reid_id = matched_track_id\n","            else:\n","                if not hasattr(tracker, 'reid_id'):\n","                    tracker.reid_id = tracker.track_id\n","\n","            # Store/update descriptor for current player\n","            if descriptor is not None:\n","                store_pose_descriptor(tracker.track_id, descriptor, frame_count)\n","\n","            # Crop torso for jersey region\n","            roi_x1 = x1 + int(0.2 * (x2 - x1))\n","            roi_x2 = x1 + int(0.8 * (x2 - x1))\n","            roi_y1 = y1 + int(0.2 * (y2 - y1))\n","            roi_y2 = y1 + int(0.6 * (y2 - y1))\n","\n","            jersey_crop = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n","            dom_color = None\n","\n","            if jersey_crop.size != 0 and roi_y2 > roi_y1 and roi_x2 > roi_x1:\n","                hsv_crop = cv2.cvtColor(jersey_crop, cv2.COLOR_BGR2HSV)\n","                dom_color = get_dominant_color(hsv_crop)\n","\n","                if dom_color is not None:\n","                    if locked_team_colors is None:\n","                        color_samples.append(dom_color)\n","                    else:\n","                        # Only include in samples if color matches one of the teams\n","                        dists = [\n","                            np.linalg.norm(dom_color - team_color)\n","                            for team_color in locked_team_colors\n","                        ]\n","\n","                        if min(dists) <= COLOR_DISTANCE_THRESHOLD:\n","                            color_samples.append(dom_color)\n","                        else:\n","                            # This color does not match any known team â€“ exclude from team assignment\n","                            dom_color = None\n","\n","            tracker.color = dom_color\n","            track_list.append(tracker)\n","\n","        # Lock team colors after collecting enough samples\n","        if locked_team_colors is None and len(color_samples) >= 50:\n","            kmeans = KMeans(n_clusters=2, random_state=42).fit(color_samples)\n","            locked_team_colors = kmeans.cluster_centers_\n","\n","        team_colors = locked_team_colors if locked_team_colors is not None else []\n","\n","        # Draw players with label\n","        for tracker in track_list:\n","            x1, y1, x2, y2 = map(int, tracker.to_tlbr())\n","            track_id = getattr(tracker, 'reid_id', tracker.track_id)\n","            dom_color = tracker.color\n","            player_conf = tracker.det_conf\n","\n","            player_label = f\"Player {player_conf:.2f}\"\n","\n","            team_label = \"\"\n","            box_color = (255, 255, 255)\n","\n","            if dom_color is not None and len(team_colors) == 2:\n","                dists = [\n","                    np.linalg.norm(dom_color - team_color)\n","                    for team_color in team_colors\n","                ]\n","\n","                if min(dists) <= COLOR_DISTANCE_THRESHOLD:\n","                    team_idx = int(np.argmin(dists))\n","                    team_label = f\"Team {'A' if team_idx == 0 else 'B'} #{track_id}\"\n","\n","            # Draw bounding box\n","            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n","\n","            label_y = y1 - 10\n","\n","            if team_label:\n","                # Draw two-line label: player on top, team below\n","                cv2.putText(frame, player_label, (x1, label_y - 20),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n","                cv2.putText(frame, team_label, (x1, label_y),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n","            else:\n","                # Draw one-line label only\n","                cv2.putText(frame, player_label, (x1, label_y),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n","\n","        # Overlay current frame number (top-left)\n","        if debug:\n","            cv2.putText(frame, f\"Frame: {frame_count}\", (10, 30),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n","\n","        out.write(frame)\n","        frame_count += 1\n","\n","        clean_old_pose_descriptors(frame_count)\n","\n","        if frame_count % 100 == 0:\n","            print(f\"Processed {frame_count} frames...\")\n","\n","    cap.release()\n","    out.release()\n","    print(f\"Processing complete. Output saved to: {output_path}\\n\")\n","\n","    # Display performance metrics\n","    if all_confidences:\n","        print(\"YOLO Detection Confidence Stats (players only):\")\n","        print(f\"  Mean: {np.mean(all_confidences):.4f}\")\n","        print(f\"  Median: {np.median(all_confidences):.4f}\")\n","        print(f\"  Std Dev: {np.std(all_confidences):.4f}\")\n","        print(f\"  Max: {np.max(all_confidences):.4f}\")\n","        print(f\"  Min: {np.min(all_confidences):.4f}\")\n","    else:\n","        print(\"No valid player detections found to compute confidence stats.\")\n","\n","# Run the processing function\n","process_video(video_path, output_path, skip_seconds=70, debug=False)"],"metadata":{"id":"7My9vF2lgIrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLreyCubfGC5"},"outputs":[],"source":["# from google.colab import files\n","# files.download('output_processed.mp4')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"mount_file_id":"1y8Ek1A_RqzWxMOWmuUFWLSLuQRXj5Qq-","authorship_tag":"ABX9TyOBP06PLclMjEtzITFCytcN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}